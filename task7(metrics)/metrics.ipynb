{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "source": [
    "import pandas as pd\n",
    "import sklearn as skl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import linalg as LA"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "source": [
    "# 1. Загрузите файл classification.csv\n",
    "# В нем записаны истинные классы объектов выборки (колонка true) и ответы некоторого классификатора (колонка predicted).\n",
    "\n",
    "clft = pd.read_csv('classification.csv'); clft\n",
    "\n",
    "# 2. Заполните таблицу ошибок классификации:\n",
    "\n",
    "#                    |Actual Positive   | Actual Negative\n",
    "# Actual Positive    |       TP         |       FP\n",
    "# Predicted Negative |       FN         |       TN\n",
    "\n",
    "# Для этого подсчитайте величины TP, FP, FN и TN согласно их определениям. \n",
    "# Например, FP — это количество объектов, имеющих класс 0, но отнесенных алгоритмом к классу 1. \n",
    "# Ответ в данном вопросе — четыре числа через пробел.\n",
    "\n",
    "TP_obj = clft[(clft.true==1)]\n",
    "FP_obj = clft[(clft.true==0)&(clft.pred==1)]\n",
    "FN_obj = clft[(clft.true==1)&(clft.pred==0)]\n",
    "TN_obj = clft[(clft.true==0)]\n",
    "\n",
    "TP = len(TP_obj)\n",
    "FP = len(FP_obj)\n",
    "FN = len(FN_obj)\n",
    "TN = len(TN_obj)\n",
    "\n",
    "print(TP, FP, FN, TN)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "102 34 59 98\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "source": [
    "# 3. Посчитайте основные метрики качества классификатора:\n",
    "#   • Accuracy (доля верно угаданных) — sklearn.metrics.accuracy_score\n",
    "#   • Precision (точность) — sklearn.metrics.accuracy.precision_score \n",
    "#   • Recall (полнота) — sklearn.metrics.recall_score\n",
    "#   • F-мера — sklearn.metrics.f1_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "acc = accuracy_score(clft.true, clft.pred)\n",
    "pre = precision_score(clft.true, clft.pred)\n",
    "recall = recall_score(clft.true, clft.pred)\n",
    "F = f1_score(clft.true, clft.pred)\n",
    "\n",
    "print(acc, pre, recall, F)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.535 0.5584415584415584 0.4215686274509804 0.48044692737430167\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "source": [
    "# 4. Имеется четыре обученных классификатора. \n",
    "# В файле scores.csv записаны истинные классы и значения степени принадлежности положительному классу для каждого классификатора на некоторой выборке:\n",
    "#   • для логистической регрессии — вероятность положительного класса (колонка score_logreg),\n",
    "#   • для SVM—отступ от разделяющей поверхности (колонкаscore_svm),\n",
    "#   • для метрического алгоритма — взвешенная сумма классов соcедей (колонка score_knn),\n",
    "#   • для решающего дерева — доля положительных объектов в листе (колонка score_tree).\n",
    "# Загрузите этот файл.\n",
    "\n",
    "scores = pd.read_csv('scores.csv'); scores\n",
    "\n",
    "# 5. Посчитайте площадь под ROC-кривой для каждого классификатора. \n",
    "# Какой классификатор имеет наибольшее значение метрики AUC-ROC (укажите название столбца с ответами этого классификатора)? \n",
    "# Воспользуйтесь функцией sklearn.metrics.roc_auc_score\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "for name in scores.columns[1:]:\n",
    "    print(roc_auc_score(scores.true, scores[name]))\n",
    "\n",
    "# 6. Какой классификатор достигает наибольшей точности (Precision) при полноте (Recall) не менее 70% \n",
    "# (укажите название столбца с ответами этого классификатора)? \n",
    "# Какое значение точности при этом получается?\n",
    "# Чтобы получить ответ на этот вопрос, найдите все точки precision-recall-кривой с помощью функции sklearn.metrics.precision_recall_curve. \n",
    "# Она возвращает три массива: precision, recall, thresholds. \n",
    "# В них записаны точность и полнота при определенных порогах, указанных в массиве thresholds. \n",
    "# Найдите максимальной значение точности среди тех записей, для которых полнота не меньше, чем 0.7.\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "max_pre = dict()\n",
    "for name in scores.columns[1:]:\n",
    "    precision, recall, thresholds = precision_recall_curve(scores.true, scores[name])\n",
    "    max_pre[name] = max(precision[recall>=0.7])\n",
    "\n",
    "max_pre"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.719187675070028\n",
      "0.7086834733893557\n",
      "0.6351540616246498\n",
      "0.6919267707082833\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'score_logreg': 0.6302521008403361,\n",
       " 'score_svm': 0.6228070175438597,\n",
       " 'score_knn': 0.6065573770491803,\n",
       " 'score_tree': 0.6517857142857143}"
      ]
     },
     "metadata": {},
     "execution_count": 152
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "d040b272fbf032b55586873b2ca8d3a5c5e5550394b053ef8ce70fe1327b555a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}